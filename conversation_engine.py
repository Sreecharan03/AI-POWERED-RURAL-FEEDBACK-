"""
JanSpandana.AI - ULTRA-CONCISE AI-Powered Conversation Engine
Revolutionary approach: Let AI drive conversation flow with STRICT BREVITY for rural voice-first design

CORE PHILOSOPHY:
- AI understands context and user intent
- MAXIMUM 15 words per response for voice optimization
- ONE question at a time for rural users
- Intelligent sector identification without keyword matching
- Adaptive conversation flow with cultural sensitivity

USAGE:
This replaces rigid conversation engines with true AI intelligence optimized for rural voice conversations.
All conversation decisions are made by AI with strict length constraints.
"""

import os
import json
import asyncio
import logging
from typing import Dict, List, Any, Optional, Tuple
from datetime import datetime, timezone
from enum import Enum

# Gemini AI
import google.generativeai as genai
from data_processor import save_conversation_to_database
from database import db_ops, DatabaseOperations
from dotenv import load_dotenv

# Load environment
load_dotenv()

# Configure logging
logging.basicConfig(level=logging.INFO)
logger = logging.getLogger(__name__)

class ConversationStage(Enum):
    """Conversation flow stages - now AI-driven"""
    GREETING = "greeting"
    NAME_COLLECTION = "name_collection"
    SECTOR_IDENTIFICATION = "sector_identification"
    DETAILED_INQUIRY = "detailed_inquiry"
    CONFIRMATION = "confirmation"
    CONCLUSION = "conclusion"

class GenderDetection(Enum):
    """Gender detection based on Telugu names"""
    MALE = "male"
    FEMALE = "female"
    UNKNOWN = "unknown"

class UltraConciseJanSpandanaAI:
    """
    Revolutionary AI-Powered Conversation Engine with STRICT BREVITY
    Zero hardcoded questions - Pure AI intelligence with rural voice optimization
    """
    
    def __init__(self):
        self.api_key = os.getenv('GEMINI_API_KEY')
        if not self.api_key:
            raise ValueError("Gemini API key not found in environment")
        
        # Configure Gemini
        genai.configure(api_key=self.api_key)
        self.model = genai.GenerativeModel('gemini-2.5-flash')
        
        # Initialize database operations
        self.db_ops = db_ops
        
        # Conversation state management
        self.active_conversations = {}
        
        # AI KNOWLEDGE BASE - Context for intelligent responses
        self.ai_context = {
            "identity": "JanSpandana.AI - ‡∞µ‡±á‡∞¶‡∞ø‡∞ï ‡∞Ü‡∞Ø‡∞æ ‡∞™‡±ç‡∞∞‡∞ú‡∞æ ‡∞∏‡∞Æ‡∞∏‡±ç‡∞Ø‡∞≤ ‡∞™‡∞∞‡∞ø‡∞∑‡±ç‡∞ï‡∞æ‡∞∞‡∞Ç ‡∞ï‡±ã‡∞∏‡∞Ç",
            "personality": "‡∞∏‡∞π‡∞æ‡∞®‡±Å‡∞≠‡±Ç‡∞§‡∞ø‡∞ó‡∞≤, ‡∞∏‡∞π‡∞æ‡∞Ø‡∞ï‡∞∞‡∞Æ‡±à‡∞® AI - ‡∞ó‡±ç‡∞∞‡∞æ‡∞Æ‡±Ä‡∞£ ‡∞™‡±ç‡∞∞‡∞ú‡∞≤‡∞§‡±ã ‡∞ó‡±å‡∞∞‡∞µ‡∞Ç‡∞ó‡∞æ ‡∞Æ‡∞æ‡∞ü‡±ç‡∞≤‡∞æ‡∞°‡±Å‡∞§‡±Å‡∞Ç‡∞¶‡∞ø",
            "sectors": ["‡∞µ‡±à‡∞¶‡±ç‡∞Ø ‡∞∏‡±á‡∞µ‡∞≤‡±Å", "‡∞Æ‡±å‡∞≤‡∞ø‡∞ï ‡∞µ‡∞∏‡∞§‡±Å‡∞≤‡±Å", "‡∞µ‡∞ø‡∞¶‡±ç‡∞Ø‡∞æ ‡∞∏‡±á‡∞µ‡∞≤‡±Å", "‡∞∏‡∞Ç‡∞ï‡±ç‡∞∑‡±á‡∞Æ ‡∞™‡∞•‡∞ï‡∞æ‡∞≤‡±Å"],
            "government_schemes": {
                "YSR ‡∞∞‡±à‡∞§‡±Å ‡∞≠‡∞∞‡±ã‡∞∏‡∞æ": "‡∞µ‡±ç‡∞Ø‡∞µ‡∞∏‡∞æ‡∞Ø ‡∞∞‡∞Ç‡∞ó‡∞Ç - ‡∞∏‡∞Ç‡∞µ‡∞§‡±ç‡∞∏‡∞∞‡∞æ‡∞®‡∞ø‡∞ï‡∞ø 13500 ‡∞∞‡±Ç‡∞™‡∞æ‡∞Ø‡∞≤‡±Å",
                "‡∞Ö‡∞Æ‡±ç‡∞Æ ‡∞µ‡±ã‡∞°‡∞ø": "‡∞µ‡∞ø‡∞¶‡±ç‡∞Ø‡∞æ ‡∞∞‡∞Ç‡∞ó‡∞Ç - ‡∞™‡∞ø‡∞≤‡±ç‡∞≤‡∞≤ ‡∞µ‡∞ø‡∞¶‡±ç‡∞Ø ‡∞ï‡±ã‡∞∏‡∞Ç ‡∞∏‡∞Ç‡∞µ‡∞§‡±ç‡∞∏‡∞∞‡∞æ‡∞®‡∞ø‡∞ï‡∞ø 15000 ‡∞∞‡±Ç‡∞™‡∞æ‡∞Ø‡∞≤‡±Å", 
                "YSR ‡∞™‡±Ü‡∞®‡±ç‡∞∑‡∞®‡±ç ‡∞ï‡∞æ‡∞Ç‡∞ï": "‡∞∏‡∞Ç‡∞ï‡±ç‡∞∑‡±á‡∞Æ ‡∞∞‡∞Ç‡∞ó‡∞Ç - ‡∞µ‡±É‡∞¶‡±ç‡∞ß‡±Å‡∞≤‡±Å, ‡∞µ‡∞ø‡∞ï‡∞≤‡∞æ‡∞Ç‡∞ó‡±Å‡∞≤‡∞ï‡±Å ‡∞Æ‡∞æ‡∞∏‡∞ø‡∞ï‡∞Ç 3000 ‡∞µ‡∞∞‡∞ï‡±Å",
                "‡∞ú‡∞ó‡∞®‡±ç‡∞®‡∞æ‡∞• ‡∞Ö‡∞®‡±ç‡∞® ‡∞ï‡∞Ç‡∞ü‡±Ä‡∞∞‡±Å": "‡∞Ü‡∞π‡∞æ‡∞∞ ‡∞≠‡∞¶‡±ç‡∞∞‡∞§ - ‡∞â‡∞ö‡∞ø‡∞§ ‡∞¨‡∞ø‡∞Ø‡±ç‡∞Ø‡∞Ç ‡∞™‡∞•‡∞ï‡∞Ç",
                "‡∞Ü‡∞∞‡±ã‡∞ó‡±ç‡∞Ø‡∞∂‡±ç‡∞∞‡±Ä": "‡∞µ‡±à‡∞¶‡±ç‡∞Ø ‡∞∞‡∞Ç‡∞ó‡∞Ç - 5 ‡∞≤‡∞ï‡±ç‡∞∑‡∞≤ ‡∞µ‡∞∞‡∞ï‡±Å ‡∞µ‡±à‡∞¶‡±ç‡∞Ø ‡∞∏‡±á‡∞µ‡∞≤‡±Å"
            },
            "cultural_context": "‡∞Ü‡∞Ç‡∞ß‡±ç‡∞∞ ‡∞™‡±ç‡∞∞‡∞¶‡±á‡∞∂‡±ç ‡∞ó‡±ç‡∞∞‡∞æ‡∞Æ‡±Ä‡∞£ ‡∞∏‡∞Ç‡∞∏‡±ç‡∞ï‡±É‡∞§‡∞ø‡∞®‡∞ø ‡∞ó‡±å‡∞∞‡∞µ‡∞ø‡∞∏‡±ç‡∞§‡±Å‡∞Ç‡∞¶‡∞ø"
        }
    
    async def ai_detect_gender_from_name(self, name: str) -> str:
        """
        AI-powered gender detection from Telugu names
        More accurate than hardcoded patterns
        """
        try:
            prompt = f"""
            Telugu name: "{name}"
            
            Is this typically a male or female name in Telugu/Andhra Pradesh culture?
            Consider:
            - Traditional Telugu naming patterns
            - Common suffixes and prefixes
            - Cultural context
            
            Respond with ONLY: "male", "female", or "unknown"
            """
            
            response = await asyncio.to_thread(self.model.generate_content, prompt)
            gender = response.text.strip().lower()
            
            if gender in ['male', 'female', 'unknown']:
                return gender
            return 'unknown'
            
        except Exception as e:
            logger.warning(f"AI gender detection failed: {e}")
            return 'unknown'
    
    async def ai_identify_sector(self, user_input: str, conversation_context: Dict) -> Optional[str]:
        """
        AI-powered sector identification
        Understands context, intent, and nuance - no keyword matching!
        """
        try:
            prompt = f"""
            You are JanSpandana.AI analyzing a citizen's concern in Telugu.
            
            User said: "{user_input}"
            Conversation context: User is from {conversation_context.get('village_name', 'unknown village')}
            
            Which government service sector does this relate to?
            
            SECTORS:
            1. ‡∞µ‡±à‡∞¶‡±ç‡∞Ø ‡∞∏‡±á‡∞µ‡∞≤‡±Å (Health/Medical) - doctors, hospitals, medicines, health centers, diseases
            2. ‡∞Æ‡±å‡∞≤‡∞ø‡∞ï ‡∞µ‡∞∏‡∞§‡±Å‡∞≤‡±Å (Infrastructure) - roads, water supply, electricity, drainage, transport
            3. ‡∞µ‡∞ø‡∞¶‡±ç‡∞Ø‡∞æ ‡∞∏‡±á‡∞µ‡∞≤‡±Å (Education) - schools, teachers, education quality, children's learning
            4. ‡∞∏‡∞Ç‡∞ï‡±ç‡∞∑‡±á‡∞Æ ‡∞™‡∞•‡∞ï‡∞æ‡∞≤‡±Å (Welfare Schemes) - pensions, ration cards, government benefits
            
            IMPORTANT:
            - Consider the MEANING and INTENT, not just keywords
            - Understand context and implications
            - If user mentions multiple sectors, pick the PRIMARY concern
            - If unclear, choose the most likely sector based on context
            
            Respond with ONLY the Telugu sector name (e.g., "‡∞µ‡±à‡∞¶‡±ç‡∞Ø ‡∞∏‡±á‡∞µ‡∞≤‡±Å")
            If truly unclear, respond with "unclear"
            """
            
            response = await asyncio.to_thread(self.model.generate_content, prompt)
            identified_sector = response.text.strip()
            
            # Validate response
            valid_sectors = ["‡∞µ‡±à‡∞¶‡±ç‡∞Ø ‡∞∏‡±á‡∞µ‡∞≤‡±Å", "‡∞Æ‡±å‡∞≤‡∞ø‡∞ï ‡∞µ‡∞∏‡∞§‡±Å‡∞≤‡±Å", "‡∞µ‡∞ø‡∞¶‡±ç‡∞Ø‡∞æ ‡∞∏‡±á‡∞µ‡∞≤‡±Å", "‡∞∏‡∞Ç‡∞ï‡±ç‡∞∑‡±á‡∞Æ ‡∞™‡∞•‡∞ï‡∞æ‡∞≤‡±Å"]
            if identified_sector in valid_sectors:
                logger.info(f"AI identified sector: {identified_sector}")
                return identified_sector
            
            logger.warning(f"AI sector identification unclear: {identified_sector}")
            return None
            
        except Exception as e:
            logger.error(f"AI sector identification failed: {e}")
            return None
    
    async def ai_generate_dynamic_response(self, stage: ConversationStage, 
                                         conversation_state: Dict, user_input: str) -> Dict[str, Any]:
        """
        AI generates ULTRA-CONCISE responses for rural voice-first conversations
        """
        try:
            # Build ultra-strict context for AI
            context = self._build_ai_context(stage, conversation_state, user_input)
            
            # Generate AI response with strict constraints
            response = await asyncio.to_thread(self.model.generate_content, context)
            response_text = response.text
            
            # Parse AI response
            structured_response = await self._parse_ai_response(response_text, stage, conversation_state)
            
            return structured_response
            
        except Exception as e:
            logger.error(f"AI response generation failed: {str(e)}")
            return self._get_fallback_response(stage, conversation_state)
    
    def _build_ai_context(self, stage: ConversationStage, state: Dict, user_input: str) -> str:
        """
        Build ULTRA-CONCISE context for AI - enforces rural voice-friendly brevity
        """
        user_name = state.get('user_name', '')
        user_gender = state.get('user_gender', 'unknown')
        village_name = state.get('village_name', '')
        identified_sector = state.get('identified_sector', '')
        conversation_log = state.get('conversation_log', [])
        
        # Determine appropriate honorific
        honorific = self._get_honorific(user_name, user_gender)
        
        # Ultra-strict brevity prompt
        base_context = f"""
You are JanSpandana.AI - Telugu grievance assistant for rural AP.

üö® CRITICAL CONSTRAINTS - NEVER VIOLATE:
- MAXIMUM 15 words in Telugu response
- Ask ONLY ONE simple question
- Use conversational rural Telugu
- NO explanations, NO repetitions, NO multiple questions
- Be direct and warm

CURRENT SITUATION:
User: {user_name} {honorific}
Village: {village_name} 
Stage: {stage.value}
Last input: "{user_input}"

STAGE-SPECIFIC INSTRUCTIONS:
"""

        # Stage-specific ultra-brief instructions
        if stage == ConversationStage.GREETING:
            base_context += """
GREETING: Welcome warmly and ask for name only.
EXAMPLE: "‡∞®‡∞Æ‡∞∏‡±ç‡∞ï‡∞æ‡∞∞‡∞Ç! ‡∞Æ‡±Ä ‡∞™‡±á‡∞∞‡±Å ‡∞è‡∞Æ‡∞ø‡∞ü‡∞ø?"
"""
            
        elif stage == ConversationStage.NAME_COLLECTION:
            base_context += f"""
NAME_COLLECTION: Thank for name, ask village only.
EXAMPLE: "‡∞∏‡±ç‡∞µ‡∞æ‡∞ó‡∞§‡∞Ç {user_name} {honorific}! ‡∞Æ‡±Ä ‡∞ó‡±ç‡∞∞‡∞æ‡∞Æ‡∞Ç ‡∞è‡∞¶‡∞ø?"
"""
            
        elif stage == ConversationStage.SECTOR_IDENTIFICATION:
            base_context += f"""
SECTOR_IDENTIFICATION: Ask about problem type briefly.
EXAMPLE: "{honorific}, ‡∞è ‡∞µ‡∞ø‡∞∑‡∞Ø‡∞Ç‡∞≤‡±ã ‡∞∏‡∞Æ‡∞∏‡±ç‡∞Ø ‡∞â‡∞Ç‡∞¶‡∞ø?"
"""
            
        elif stage == ConversationStage.DETAILED_INQUIRY:
            base_context += f"""
DETAILED_INQUIRY: Ask ONE specific detail about their {identified_sector} problem.
EXAMPLES:
- "‡∞á‡∞¶‡∞ø ‡∞é‡∞Ç‡∞§‡∞ï‡∞æ‡∞≤‡∞Ç‡∞ó‡∞æ ‡∞â‡∞Ç‡∞¶‡∞ø?"
- "‡∞é‡∞Ç‡∞§ ‡∞Æ‡∞Ç‡∞¶‡∞ø ‡∞™‡±ç‡∞∞‡∞≠‡∞æ‡∞µ‡∞ø‡∞§‡∞Æ‡∞Ø‡±ç‡∞Ø‡∞æ‡∞∞‡±Å?"
- "‡∞é‡∞µ‡∞∞‡∞ø‡∞ï‡∞ø ‡∞ö‡±Ü‡∞™‡±ç‡∞™‡∞æ‡∞∞‡±Å ‡∞á‡∞Ç‡∞§‡∞ï‡±Å‡∞Æ‡±Å‡∞Ç‡∞¶‡±Å?"
"""
            
        elif stage == ConversationStage.CONFIRMATION:
            base_context += f"""
CONFIRMATION: Briefly confirm understanding.
EXAMPLE: "‡∞Ö‡∞∞‡±ç‡∞•‡∞Æ‡±à‡∞Ç‡∞¶‡∞ø {honorific}. ‡∞Æ‡∞∞‡±á‡∞Æ‡±à‡∞®‡∞æ ‡∞ö‡±Ü‡∞™‡±ç‡∞™‡∞æ‡∞≤‡∞æ?"
"""
            
        elif stage == ConversationStage.CONCLUSION:
            base_context += f"""
CONCLUSION: Thank briefly and promise action.
EXAMPLE: "‡∞ß‡∞®‡±ç‡∞Ø‡∞µ‡∞æ‡∞¶‡∞æ‡∞≤‡±Å {honorific}! ‡∞Æ‡±Ä ‡∞∏‡∞Æ‡∞∏‡±ç‡∞Ø ‡∞Ö‡∞ß‡∞ø‡∞ï‡∞æ‡∞∞‡±Å‡∞≤‡∞ï‡±Å ‡∞™‡∞Ç‡∞™‡∞ø‡∞∏‡±ç‡∞§‡∞æ‡∞Ç."
"""

        base_context += f"""

RESPONSE REQUIREMENTS:
Return ONLY this JSON format:
{{
    "telugu_response": "10-15 word Telugu response with ONE question",
    "english_summary": "Brief English summary",
    "stage_complete": true/false,
    "next_stage": "stage_name_or_null",
    "confidence_score": 0.8,
    "reasoning": "Why this response"
}}

GOOD RESPONSE EXAMPLES (COPY THIS STYLE):
- "‡∞Ö‡∞®‡±ç‡∞®, ‡∞Æ‡±Ä ‡∞™‡±á‡∞∞‡±Å ‡∞è‡∞Æ‡∞ø‡∞ü‡∞ø?" (6 words - PERFECT)
- "‡∞ó‡±ç‡∞∞‡∞æ‡∞Æ‡∞Ç ‡∞™‡±á‡∞∞‡±Å ‡∞ö‡±Ü‡∞™‡±ç‡∞™‡∞Ç‡∞°‡∞ø ‡∞Ö‡∞ï‡±ç‡∞ï" (5 words - PERFECT)  
- "‡∞è ‡∞µ‡∞ø‡∞∑‡∞Ø‡∞Ç‡∞≤‡±ã ‡∞∏‡∞Æ‡∞∏‡±ç‡∞Ø ‡∞â‡∞Ç‡∞¶‡∞ø?" (5 words - PERFECT)
- "‡∞á‡∞¶‡∞ø ‡∞é‡∞Ç‡∞§‡∞ï‡∞æ‡∞≤‡∞Ç‡∞ó‡∞æ ‡∞â‡∞Ç‡∞¶‡∞ø?" (4 words - PERFECT)
- "‡∞Æ‡∞∞‡±á‡∞Æ‡±à‡∞®‡∞æ ‡∞ö‡±Ü‡∞™‡±ç‡∞™‡∞æ‡∞≤‡∞æ?" (3 words - PERFECT)

BAD EXAMPLES (NEVER DO THIS):
‚ùå "‡∞Æ‡±Ä‡∞∞‡±Å ‡∞ö‡±Ü‡∞™‡±ç‡∞™‡∞ø‡∞® ‡∞∏‡∞Æ‡∞∏‡±ç‡∞Ø ‡∞®‡∞æ‡∞ï‡±Å ‡∞Ö‡∞∞‡±ç‡∞•‡∞Æ‡±à‡∞Ç‡∞¶‡∞ø. ‡∞∏‡±ç‡∞ï‡±Ç‡∞≤‡±ç‡∞≤‡±ã ‡∞ü‡±Ä‡∞ö‡∞∞‡±ç‡∞≤‡±Å ‡∞§‡∞ï‡±ç‡∞ï‡±Å‡∞µ‡∞ó‡∞æ ‡∞â‡∞®‡±ç‡∞®‡∞æ‡∞∞‡∞®‡∞ø..."
‚ùå Any response longer than 15 words
‚ùå Multiple questions in one response
‚ùå Repeating what user said

üéØ GENERATE ULTRA-SHORT RESPONSE NOW (MAX 15 WORDS):
"""
        
        return base_context
    
    async def _parse_ai_response(self, ai_response: str, stage: ConversationStage, state: Dict) -> Dict[str, Any]:
        """
        Parse AI response and structure it for application use
        More flexible than rigid JSON parsing
        """
        try:
            # Try to extract JSON from response
            start = ai_response.find('{')
            end = ai_response.rfind('}') + 1
            
            if start != -1 and end > start:
                json_str = ai_response[start:end]
                parsed_response = json.loads(json_str)
                
                # Validate required fields
                required_fields = ['telugu_response', 'stage_complete']
                for field in required_fields:
                    if field not in parsed_response:
                        raise ValueError(f"Missing required field: {field}")
                
                # Enforce length constraint
                telugu_response = parsed_response['telugu_response']
                word_count = len(telugu_response.split())
                if word_count > 15:
                    logger.warning(f"AI response too long ({word_count} words), truncating")
                    # Take first 15 words and add question mark if missing
                    words = telugu_response.split()[:15]
                    parsed_response['telugu_response'] = ' '.join(words)
                    if not parsed_response['telugu_response'].endswith('?'):
                        parsed_response['telugu_response'] += '?'
                
            else:
                # Fallback: extract Telugu response from raw text
                telugu_text = ai_response.strip()
                # Clean up common AI artifacts
                telugu_text = telugu_text.replace('```json', '').replace('```', '').strip()
                
                # Truncate if too long
                words = telugu_text.split()
                if len(words) > 15:
                    telugu_text = ' '.join(words[:15]) + '?'
                
                parsed_response = {
                    "telugu_response": telugu_text,
                    "english_summary": "AI response (parsed from text)",
                    "stage_complete": True,
                    "confidence_score": 0.7,
                    "reasoning": "Fallback parsing used"
                }
            
            # Add metadata
            parsed_response.update({
                'current_stage': stage.value,
                'timestamp': datetime.now(timezone.utc).isoformat(),
                'conversation_id': state.get('conversation_id'),
                'processing_successful': True,
                'ai_powered': True,
                'word_count': len(parsed_response['telugu_response'].split())
            })
            
            return parsed_response
            
        except json.JSONDecodeError as e:
            logger.error(f"JSON parsing failed: {str(e)}")
            return self._get_fallback_response(stage, state)
        except Exception as e:
            logger.error(f"Response parsing failed: {str(e)}")
            return self._get_fallback_response(stage, state)
    
    def _get_fallback_response(self, stage: ConversationStage, state: Dict) -> Dict[str, Any]:
        """
        Ultra-short fallback responses when AI fails
        """
        user_name = state.get('user_name', '')
        user_gender = state.get('user_gender', 'unknown')
        honorific = self._get_honorific(user_name, user_gender)
        
        fallback_responses = {
            ConversationStage.GREETING: "‡∞®‡∞Æ‡∞∏‡±ç‡∞ï‡∞æ‡∞∞‡∞Ç! ‡∞Æ‡±Ä ‡∞™‡±á‡∞∞‡±Å ‡∞è‡∞Æ‡∞ø‡∞ü‡∞ø?",
            ConversationStage.NAME_COLLECTION: f"‡∞∏‡±ç‡∞µ‡∞æ‡∞ó‡∞§‡∞Ç {user_name} {honorific}! ‡∞Æ‡±Ä ‡∞ó‡±ç‡∞∞‡∞æ‡∞Æ‡∞Ç ‡∞è‡∞¶‡∞ø?",
            ConversationStage.SECTOR_IDENTIFICATION: f"{honorific}, ‡∞è ‡∞µ‡∞ø‡∞∑‡∞Ø‡∞Ç‡∞≤‡±ã ‡∞∏‡∞Æ‡∞∏‡±ç‡∞Ø ‡∞â‡∞Ç‡∞¶‡∞ø?",
            ConversationStage.DETAILED_INQUIRY: f"‡∞µ‡∞ø‡∞µ‡∞∞‡∞Ç‡∞ó‡∞æ ‡∞ö‡±Ü‡∞™‡±ç‡∞™‡∞Ç‡∞°‡∞ø {honorific}",
            ConversationStage.CONFIRMATION: f"‡∞Ö‡∞∞‡±ç‡∞•‡∞Æ‡±à‡∞Ç‡∞¶‡∞ø {honorific}. ‡∞Æ‡∞∞‡±á‡∞Æ‡±à‡∞®‡∞æ ‡∞ö‡±Ü‡∞™‡±ç‡∞™‡∞æ‡∞≤‡∞æ?",
            ConversationStage.CONCLUSION: f"‡∞ß‡∞®‡±ç‡∞Ø‡∞µ‡∞æ‡∞¶‡∞æ‡∞≤‡±Å {honorific}! ‡∞Æ‡±Ä ‡∞∏‡∞Æ‡∞∏‡±ç‡∞Ø‡∞≤‡∞®‡±Å ‡∞™‡∞∞‡∞ø‡∞∑‡±ç‡∞ï‡∞∞‡∞ø‡∞∏‡±ç‡∞§‡∞æ‡∞Ç."
        }
        
        return {
            'telugu_response': fallback_responses.get(stage, "‡∞¶‡∞Ø‡∞ö‡±á‡∞∏‡∞ø ‡∞Æ‡∞≥‡±ç‡∞≤‡±Ä ‡∞ö‡±Ü‡∞™‡±ç‡∞™‡∞Ç‡∞°‡∞ø"),
            'english_summary': 'Fallback response due to AI processing failure',
            'stage_complete': True,
            'next_stage': self._get_next_stage(stage),
            'processing_successful': False,
            'fallback_used': True,
            'confidence_score': 0.3,
            'word_count': len(fallback_responses.get(stage, "").split())
        }
    
    def _get_next_stage(self, current_stage: ConversationStage) -> str:
        """Get the next stage in conversation flow"""
        stage_flow = {
            ConversationStage.GREETING: "name_collection",
            ConversationStage.NAME_COLLECTION: "sector_identification", 
            ConversationStage.SECTOR_IDENTIFICATION: "detailed_inquiry",
            ConversationStage.DETAILED_INQUIRY: "confirmation",
            ConversationStage.CONFIRMATION: "conclusion",
            ConversationStage.CONCLUSION: None
        }
        return stage_flow.get(current_stage)

    def _normalize_prompt(self, text: str) -> str:
        """Normalize AI prompt for repeat detection."""
        if not text:
            return ""
        return ' '.join(text.lower().replace('?', '').replace('!', '').split())

    def _is_repeat_prompt(self, state: Dict, normalized_prompt: str) -> bool:
        """
        Detect if the AI is repeating itself or stuck in the same intent.
        """
        if not normalized_prompt:
            return False

        recent = state.get('recent_ai_prompts', [])
        if normalized_prompt in recent:
            return True

        # If we've already asked multiple detailed questions, push forward
        if state.get('stage') == ConversationStage.DETAILED_INQUIRY.value:
            if len(recent) >= 3:
                return True

        return False

    def _count_stage_user_inputs(self, state: Dict, stage: ConversationStage) -> int:
        """Count how many user inputs were recorded for a given stage."""
        log = state.get('conversation_log', [])
        return len([step for step in log if step.get('stage') == stage.value and step.get('user_input')])
    
    def _get_honorific(self, name: str, gender: str) -> str:
        """
        Get appropriate Telugu honorific based on name and gender
        """
        if not name:
            return "‡∞ó‡∞æ‡∞∞‡±Ç"
            
        if gender == 'male':
            return "‡∞Ö‡∞®‡±ç‡∞®"  # Brother (respectful for males)
        elif gender == 'female':
            return "‡∞Ö‡∞ï‡±ç‡∞ï"  # Sister (respectful for females)
        else:
            return "‡∞ó‡∞æ‡∞∞‡±Ç"  # Universal respectful term
    
    def _normalize_stage(self, stage_value: Optional[str], fallback: str) -> str:
        """
        Normalize any AI-provided stage string to a valid ConversationStage value.
        Falls back to the provided fallback stage when no mapping is found.
        """
        stage_key = str(stage_value or "").strip().lower()
        
        mapping = {
            # Greeting variants
            "greeting": ConversationStage.GREETING.value,
            "intro": ConversationStage.GREETING.value,
            "welcome": ConversationStage.GREETING.value,
            
            # Name collection variants (also used when AI asks for village right after name)
            "name_collection": ConversationStage.NAME_COLLECTION.value,
            "collect_name": ConversationStage.NAME_COLLECTION.value,
            "ask_name": ConversationStage.NAME_COLLECTION.value,
            "ask_for_name": ConversationStage.NAME_COLLECTION.value,
            "get_name": ConversationStage.NAME_COLLECTION.value,
            "name": ConversationStage.NAME_COLLECTION.value,
            "name_provided": ConversationStage.NAME_COLLECTION.value,
            "ask_for_village": ConversationStage.NAME_COLLECTION.value,
            "village_prompt": ConversationStage.NAME_COLLECTION.value,
            "collect_village": ConversationStage.NAME_COLLECTION.value,
            "village_collection": ConversationStage.NAME_COLLECTION.value,
            
            # Sector identification variants
            "sector_identification": ConversationStage.SECTOR_IDENTIFICATION.value,
            "sector_choice": ConversationStage.SECTOR_IDENTIFICATION.value,
            "sector_selection": ConversationStage.SECTOR_IDENTIFICATION.value,
            "choose_sector": ConversationStage.SECTOR_IDENTIFICATION.value,
            "select_sector": ConversationStage.SECTOR_IDENTIFICATION.value,
            "sector": ConversationStage.SECTOR_IDENTIFICATION.value,
            "choose_service": ConversationStage.SECTOR_IDENTIFICATION.value,
            "select_service": ConversationStage.SECTOR_IDENTIFICATION.value,
            
            # Detailed inquiry variants
            "detailed_inquiry": ConversationStage.DETAILED_INQUIRY.value,
            "detail_inquiry": ConversationStage.DETAILED_INQUIRY.value,
            "issue_details": ConversationStage.DETAILED_INQUIRY.value,
            "problem_details": ConversationStage.DETAILED_INQUIRY.value,
            "information_gathering": ConversationStage.DETAILED_INQUIRY.value,
            "followup": ConversationStage.DETAILED_INQUIRY.value,
            "follow_up": ConversationStage.DETAILED_INQUIRY.value,
            "collect_details": ConversationStage.DETAILED_INQUIRY.value,
            "detailed_questions": ConversationStage.DETAILED_INQUIRY.value,
            
            # Confirmation variants
            "confirmation": ConversationStage.CONFIRMATION.value,
            "confirm": ConversationStage.CONFIRMATION.value,
            "review": ConversationStage.CONFIRMATION.value,
            "summary": ConversationStage.CONFIRMATION.value,
            "recap": ConversationStage.CONFIRMATION.value,
            "acknowledge": ConversationStage.CONFIRMATION.value,
            
            # Conclusion variants
            "conclusion": ConversationStage.CONCLUSION.value,
            "closing": ConversationStage.CONCLUSION.value,
            "close": ConversationStage.CONCLUSION.value,
            "end": ConversationStage.CONCLUSION.value,
            "goodbye": ConversationStage.CONCLUSION.value,
            "farewell": ConversationStage.CONCLUSION.value,
            "wrap_up": ConversationStage.CONCLUSION.value,
            "finish": ConversationStage.CONCLUSION.value,
        }
        
        return mapping.get(stage_key, fallback)

    async def start_new_conversation(self, conversation_id: str) -> Dict[str, Any]:
        """
        Initialize a new conversation session
        """
        initial_state = {
            'conversation_id': conversation_id,
            'stage': ConversationStage.GREETING.value,
            'user_name': '',
            'user_gender': 'unknown',
            'village_name': '',
            'identified_sector': '',
            'collected_issues': [],
            'conversation_log': [],
            'start_time': datetime.now(timezone.utc).isoformat(),
            'question_count': 0,
            'ai_powered': True,
            'ultra_concise_mode': True,
            'recent_ai_prompts': []
        }
        
        self.active_conversations[conversation_id] = initial_state
        
        # Generate AI greeting
        greeting_response = await self.ai_generate_dynamic_response(
            ConversationStage.GREETING, initial_state, ""
        )
        
        return {
            'conversation_id': conversation_id,
            'initial_response': greeting_response,
            'session_started': True,
            'ultra_concise_mode': True
        }
    
    async def process_user_input(self, conversation_id: str, user_input: str, 
                                audio_metadata: Optional[Dict] = None) -> Dict[str, Any]:
        """
        Process user input with ultra-concise AI intelligence
        """
        if conversation_id not in self.active_conversations:
            return {'error': 'Conversation not found', 'success': False}
        
        state = self.active_conversations[conversation_id]
        normalized_stage = self._normalize_stage(state.get('stage'), ConversationStage.GREETING.value)
        state['stage'] = normalized_stage
        current_stage = ConversationStage(normalized_stage)
        
        # AI-powered conversation state update
        await self._ai_update_conversation_state(state, user_input, current_stage)
        
        # Generate ultra-concise AI response
        ai_response = await self.ai_generate_dynamic_response(
            ConversationStage(state['stage']), state, user_input
        )

        # Prevent repetitive questioning: dedupe against recent prompts and handle per-stage progression carefully
        normalized_prompt = self._normalize_prompt(ai_response.get('telugu_response', ''))
        if self._is_repeat_prompt(state, normalized_prompt):
            current_stage = ConversationStage(state['stage'])
            # In detail stage, keep asking for specifics until we have enough detail
            if current_stage == ConversationStage.DETAILED_INQUIRY:
                detail_turns = self._count_stage_user_inputs(state, ConversationStage.DETAILED_INQUIRY)
                if detail_turns < 2:
                    ai_response['telugu_response'] = "‡∞Ö‡∞®‡±ç‡∞®, ‡∞µ‡∞ø‡∞µ‡∞∞‡∞Ç‡∞ó‡∞æ ‡∞ö‡±Ü‡∞™‡±ç‡∞™‡∞Ç‡∞°‡∞ø: ‡∞∏‡∞Æ‡∞∏‡±ç‡∞Ø ‡∞é‡∞ï‡±ç‡∞ï‡∞°, ‡∞é‡∞µ‡∞∞‡±Å, ‡∞é‡∞™‡±ç‡∞™‡∞ü‡∞ø ‡∞®‡±Å‡∞Ç‡∞ö‡∞ø?"
                    ai_response['reasoning'] = "Repeat detected in detail stage; asking for specific details"
                    ai_response['fallback_used'] = True
                else:
                    next_stage = self._get_next_stage(current_stage)
                    if next_stage:
                        state['stage'] = next_stage
                    ai_response['telugu_response'] = "‡∞∏‡∞∞‡±á, ‡∞Æ‡±Ä ‡∞µ‡∞ø‡∞µ‡∞∞‡∞æ‡∞≤‡±Å ‡∞ó‡∞Æ‡∞®‡∞ø‡∞Ç‡∞ö‡∞æ‡∞Ç. ‡∞á‡∞Ç‡∞ï‡∞æ ‡∞è‡∞Æ‡±à‡∞®‡∞æ ‡∞ú‡±ã‡∞°‡∞ø‡∞Ç‡∞ö‡∞æ‡∞≤‡∞æ ‡∞≤‡±á‡∞¶‡∞æ ‡∞Æ‡±Å‡∞ó‡∞ø‡∞Ç‡∞ö‡∞æ‡∞≤‡∞æ?"
                    ai_response['reasoning'] = "Repeat detected after sufficient detail; moving forward"
                    ai_response['fallback_used'] = True
            else:
                next_stage = self._get_next_stage(current_stage)
                if next_stage:
                    state['stage'] = next_stage
                ai_response['telugu_response'] = "‡∞∏‡∞∞‡±á, ‡∞à ‡∞µ‡∞ø‡∞∑‡∞Ø‡∞æ‡∞®‡±ç‡∞®‡∞ø ‡∞ó‡∞Æ‡∞®‡∞ø‡∞Ç‡∞ö‡∞æ‡∞®‡±Å. ‡∞á‡∞Ç‡∞ï‡±á‡∞¶‡±à‡∞®‡∞æ ‡∞ú‡±ã‡∞°‡∞ø‡∞Ç‡∞ö‡∞æ‡∞≤‡∞æ ‡∞≤‡±á‡∞¶‡∞æ ‡∞Æ‡±Å‡∞Ç‡∞¶‡±Å‡∞ï‡±Å ‡∞µ‡±Ü‡∞≥‡±ç‡∞≤‡∞æ‡∞≤‡∞æ?"
                ai_response['reasoning'] = "De-duplicated repeated question and progressed stage"
                ai_response['fallback_used'] = True
        # Track prompt history
        state['recent_ai_prompts'].append(normalized_prompt)
        if len(state['recent_ai_prompts']) > 5:
            state['recent_ai_prompts'].pop(0)
        
        # Log conversation step
        conversation_step = {
            'conversation_id': conversation_id,
            'user_input': user_input,
            'ai_response': ai_response['telugu_response'],
            'stage': state['stage'],
            'question_count': state['question_count'],
            'audio_metadata': audio_metadata,
            'timestamp': datetime.now(timezone.utc).isoformat(),
            'ai_confidence': ai_response.get('confidence_score', 0.0),
            'response_word_count': ai_response.get('word_count', 0),
            'ai_reasoning': ai_response.get('reasoning'),
            'ai_fallback_used': ai_response.get('fallback_used', False)
        }
        
        state['conversation_log'].append(conversation_step)
        state['question_count'] += 1

        # Persist step to Supabase (best-effort; don't break flow on failure)
        try:
            await db_ops.log_conversation_step(conversation_step)
        except Exception as e:
            logger.warning(f"Failed to persist conversation step: {e}")

        return {
            'success': True,
            'ai_response': ai_response,
            'conversation_state': state,
            'step_logged': True,
            'ultra_concise_mode': True
        }
    
    async def _ai_update_conversation_state(self, state: Dict, user_input: str, current_stage: ConversationStage):
        """
        AI-powered conversation state management with brevity focus
        """
        try:
            # Build context for AI state management
            context = f"""
            You are managing conversation state for JanSpandana.AI.
            
            CURRENT STATE:
            - Stage: {current_stage.value}
            - User name: {state.get('user_name', 'not_set')}
            - Village: {state.get('village_name', 'not_set')}
            - Sector: {state.get('identified_sector', 'not_set')}
            
            USER JUST SAID: "{user_input}"
            
            TASKS:
            1. Extract any new information (name, village, sector preference)
            2. Decide if we should progress to next stage
            3. Update conversation state appropriately
            
            RESPOND WITH JSON:
            {{
                "extracted_name": "name if mentioned, else null",
                "extracted_village": "village if mentioned, else null",
                "extracted_sector": "sector if identified, else null", 
                "should_progress": true/false,
                "next_stage": "stage_name if progressing",
                "reasoning": "why these decisions were made"
            }}
            """
            
            response = await asyncio.to_thread(self.model.generate_content, context)
            
            # Parse AI decision
            try:
                start = response.text.find('{')
                end = response.text.rfind('}') + 1
                if start != -1 and end > start:
                    ai_decision = json.loads(response.text[start:end])
                    
                    # Update state based on AI analysis
                    if ai_decision.get('extracted_name') and not state.get('user_name'):
                        state['user_name'] = ai_decision['extracted_name'].strip()
                        # AI-powered gender detection
                        state['user_gender'] = await self.ai_detect_gender_from_name(state['user_name'])
                    
                    if ai_decision.get('extracted_village') and not state.get('village_name'):
                        state['village_name'] = ai_decision['extracted_village'].strip()
                    
                    if ai_decision.get('extracted_sector'):
                        # Use AI sector identification for accuracy
                        identified_sector = await self.ai_identify_sector(user_input, state)
                        if identified_sector:
                            state['identified_sector'] = identified_sector
                    
                    # AI decides when to progress stages
                    if ai_decision.get('should_progress') and ai_decision.get('next_stage'):
                        state['stage'] = self._normalize_stage(
                            ai_decision.get('next_stage'),
                            self._get_next_stage(current_stage) or current_stage.value
                        )
                    
                    logger.info(f"AI state update: {ai_decision.get('reasoning', 'No reasoning provided')}")
                    
            except json.JSONDecodeError:
                logger.warning("AI state management JSON parse failed, using fallback logic")
                # Simple fallback state progression
                self._fallback_state_update(state, user_input, current_stage)
                
        except Exception as e:
            logger.error(f"AI state management failed: {e}")
            # Fallback to simple state management
            self._fallback_state_update(state, user_input, current_stage)
    
    def _fallback_state_update(self, state: Dict, user_input: str, current_stage: ConversationStage):
        """
        Simple fallback state management when AI fails
        """
        if current_stage == ConversationStage.GREETING and user_input:
            # Extract name (simple approach)
            name = user_input.strip()
            if '‡∞™‡±á‡∞∞‡±Å' in user_input:
                parts = user_input.split('‡∞™‡±á‡∞∞‡±Å')
                if len(parts) > 1:
                    name = parts[1].strip()
            state['user_name'] = name
            state['user_gender'] = 'unknown'  # Fallback
            state['stage'] = ConversationStage.NAME_COLLECTION.value
            
        elif current_stage == ConversationStage.NAME_COLLECTION and user_input:
            state['village_name'] = user_input.strip()
            state['stage'] = ConversationStage.SECTOR_IDENTIFICATION.value
            
        elif current_stage == ConversationStage.SECTOR_IDENTIFICATION and user_input:
            # Simple sector matching as fallback
            if any(word in user_input.lower() for word in ['‡∞µ‡±à‡∞¶‡±ç‡∞Ø', '‡∞°‡∞æ‡∞ï‡±ç‡∞ü‡∞∞‡±Å', '‡∞Ü‡∞∏‡±ç‡∞™‡∞§‡±ç‡∞∞‡∞ø']):
                state['identified_sector'] = '‡∞µ‡±à‡∞¶‡±ç‡∞Ø ‡∞∏‡±á‡∞µ‡∞≤‡±Å'
            elif any(word in user_input.lower() for word in ['‡∞∏‡±ç‡∞ï‡±Ç‡∞≤‡±Å', '‡∞µ‡∞ø‡∞¶‡±ç‡∞Ø', '‡∞ü‡±Ä‡∞ö‡∞∞‡±Å']):
                state['identified_sector'] = '‡∞µ‡∞ø‡∞¶‡±ç‡∞Ø‡∞æ ‡∞∏‡±á‡∞µ‡∞≤‡±Å'
            elif any(word in user_input.lower() for word in ['‡∞∞‡±ã‡∞°‡±Å', '‡∞®‡±Ä‡∞∞‡±Å', '‡∞ï‡∞∞‡±Ü‡∞Ç‡∞ü‡±ç']):
                state['identified_sector'] = '‡∞Æ‡±å‡∞≤‡∞ø‡∞ï ‡∞µ‡∞∏‡∞§‡±Å‡∞≤‡±Å'
            else:
                state['identified_sector'] = '‡∞∏‡∞Ç‡∞ï‡±ç‡∞∑‡±á‡∞Æ ‡∞™‡∞•‡∞ï‡∞æ‡∞≤‡±Å'
            state['stage'] = ConversationStage.DETAILED_INQUIRY.value
            
        # Add user input to collected issues
        if len(user_input.split()) > 2:  # Substantial input
            state['collected_issues'].append({
                'content': user_input,
                'timestamp': datetime.now(timezone.utc).isoformat(),
                'stage': state['stage']
            })
    
    async def end_conversation(self, conversation_id: str, skip_save: bool = False) -> Dict[str, Any]:
        """
        End conversation and save to database
        """
        if conversation_id not in self.active_conversations:
            return {'error': 'Conversation not found', 'success': False}
        
        state = self.active_conversations[conversation_id]

        # Allow health checks or explicit skip requests to bypass persistence
        if skip_save or conversation_id.startswith("health_check"):
            logger.info(f"Skipping database save for conversation {conversation_id} (health check/skip flag)")
            del self.active_conversations[conversation_id]
            return {
                'success': True,
                'summary': {
                    'conversation_id': conversation_id,
                    'completion_status': 'skipped_persistence',
                    'ai_powered': True,
                    'ultra_concise_mode': True
                }
            }
        
        # Prepare data for database storage
        conversation_summary = {
            'conversation_id': conversation_id,
            'user_name': state['user_name'],
            'user_gender': state['user_gender'],
            'village_name': state['village_name'],
            'identified_sector': state['identified_sector'],
            'total_questions': state['question_count'],
            'issues_collected': state['collected_issues'],
            'conversation_log': state['conversation_log'],
            'start_time': state['start_time'],
            'end_time': datetime.now(timezone.utc).isoformat(),
            'completion_status': 'completed',
            'ai_powered': True,
            'ultra_concise_mode': True
        }
        
        # Save to database using data processor
        try:
            db_result = await save_conversation_to_database(state, conversation_id)
            
            if db_result['success']:
                logger.info(f"‚úÖ Database save successful: {db_result['grievance_id']}")
                conversation_summary['database_saved'] = True
                conversation_summary['grievance_id'] = db_result['grievance_id']
                conversation_summary['user_id'] = db_result['user_id']
            else:
                logger.error(f"‚ùå Database save failed: {db_result['error']}")
                conversation_summary['database_saved'] = False
                conversation_summary['database_error'] = db_result['error']
            
            # Clean up active conversation
            del self.active_conversations[conversation_id]
            
            return {
                'success': True,
                'summary': conversation_summary
            }

        except Exception as e:
            logger.error(f"Failed to save conversation: {str(e)}")
            return {
                'success': False,
                'error': 'Failed to save conversation',
                'summary': conversation_summary
            }

# Global AI conversation engine instance
jan_spandana_ai = UltraConciseJanSpandanaAI()

# Utility functions for easy import (maintaining compatibility)
async def start_conversation(conversation_id: str) -> Dict[str, Any]:
    """Start a new conversation session"""
    return await jan_spandana_ai.start_new_conversation(conversation_id)

async def process_message(conversation_id: str, user_input: str, 
                         audio_metadata: Optional[Dict] = None) -> Dict[str, Any]:
    """Process user message and get AI response"""
    return await jan_spandana_ai.process_user_input(conversation_id, user_input, audio_metadata)

async def end_conversation_session(conversation_id: str, skip_save: bool = False) -> Dict[str, Any]:
    """End conversation and save data"""
    return await jan_spandana_ai.end_conversation(conversation_id, skip_save=skip_save)

if __name__ == "__main__":
    # Test ultra-concise conversation engine
    async def test_ultra_concise_conversation():
        print("Testing JanSpandana.AI Ultra-Concise Conversation Engine...")
        
        # Start new conversation
        conv_id = "test_concise_001"
        start_result = await start_conversation(conv_id)
        
        if start_result['session_started']:
            print("‚úÖ Ultra-concise conversation started successfully")
            print(f"Initial response: {start_result['initial_response']['telugu_response']}")
            word_count = len(start_result['initial_response']['telugu_response'].split())
            print(f"Word count: {word_count} (Target: ‚â§15)")
        else:
            print("‚ùå Failed to start conversation")
            return
        
        # Test realistic conversation flow
        test_messages = [
            "‡∞®‡∞æ ‡∞™‡±á‡∞∞‡±Å ‡∞∞‡∞Æ‡±ç‡∞Ø",
            "‡∞∂‡±ç‡∞∞‡±Ä‡∞ï‡∞æ‡∞ï‡±Å‡∞≥‡∞Ç ‡∞®‡±Å‡∞Ç‡∞ö‡∞ø ‡∞µ‡∞ö‡±ç‡∞ö‡∞æ‡∞®‡±Å",
            "‡∞µ‡∞ø‡∞¶‡±ç‡∞Ø‡∞æ ‡∞∏‡±á‡∞µ‡∞≤‡∞≤‡±ã ‡∞∏‡∞Æ‡∞∏‡±ç‡∞Ø‡∞≤‡±Å ‡∞â‡∞®‡±ç‡∞®‡∞æ‡∞Ø‡∞ø", 
            "‡∞Æ‡∞æ ‡∞ó‡±ç‡∞∞‡∞æ‡∞Æ‡∞Ç‡∞≤‡±ã ‡∞∏‡±ç‡∞ï‡±Ç‡∞≤‡±Å ‡∞ü‡±Ä‡∞ö‡∞∞‡±ç‡∞≤‡±Å ‡∞∞‡±ã‡∞ú‡±Ç ‡∞∞‡∞æ‡∞ü‡∞Ç‡∞≤‡±á‡∞¶‡±Å, ‡∞™‡∞ø‡∞≤‡±ç‡∞≤‡∞≤‡∞ï‡±Å ‡∞∏‡∞∞‡∞ø‡∞ó‡±ç‡∞ó‡∞æ ‡∞ö‡∞¶‡∞µ‡∞ü‡∞Ç‡∞≤‡±á‡∞¶‡±Å"
        ]
        
        for message in test_messages:
            print(f"\nUser: {message}")
            response = await process_message(conv_id, message)
            if response['success']:
                ai_resp = response['ai_response']
                print(f"AI: {ai_resp['telugu_response']}")
                word_count = ai_resp.get('word_count', len(ai_resp['telugu_response'].split()))
                print(f"Word count: {word_count} (Target: ‚â§15)")
                if word_count > 15:
                    print("‚ö†Ô∏è WARNING: Response exceeds 15-word limit!")
                else:
                    print("‚úÖ Within word limit")
            else:
                print(f"Error: {response}")
        
        # End conversation
        end_result = await end_conversation_session(conv_id)
        if end_result['success']:
            print("\n‚úÖ Ultra-concise conversation ended successfully")
            print("üöÄ AI-powered ultra-brief conversation completed!")
        else:
            print(f"\n‚ùå Failed to end conversation: {end_result}")
    
    asyncio.run(test_ultra_concise_conversation())
